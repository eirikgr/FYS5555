{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO \t Data type is MC\n"
     ]
    }
   ],
   "source": [
    "indir = \"/scratch/eirikgr/openData_13TeV/3lep/MC/\"\n",
    "datadir = \"/home/michael/Desktop/OpenData/data\"\n",
    "# The output file name tag to store the skim options used abvove\n",
    "datatype = indir.split(\"/\")[-1]\n",
    "# In cases there is a trailing / at the end\n",
    "if not datatype: datatype = indir.split(\"/\")[-2]\n",
    "print(\"INFO \\t Data type is {:s}\".format(datatype))\n",
    "skimtag = \"2L_pt25_25_met50\"\n",
    "\n",
    "# SM_Backgrounds_2L_pt25_25_met50_num_10.h5\n",
    "\n",
    "rBackgroundEvents = 0.5\n",
    "rSignalEvents = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgdir = \"/scratch/eirikgr/openData_13TeV/3lep/MC/\"\n",
    "sigdir = \"/scratch/eirikgr/openData_13TeV/3lep/MC/\"\n",
    "# The output file name tag to store the skim options used abvove\n",
    "datatype = bkgdir.split(\"/\")[-1]\n",
    "# In cases there is a trailing / at the end\n",
    "if not datatype: datatype = bkgir.split(\"/\")[-2]\n",
    "print(\"INFO \\t Data type is {:s}\".format(datatype))\n",
    "skimtag = \"2L_pt25_25_met50\"\n",
    "\n",
    "# SM_Backgrounds_2L_pt25_25_met50_num_10.h5\n",
    "\n",
    "rBackgroundEvents = 0.5\n",
    "rSignalEvents = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_files = [f for f in listdir(indir) if (f.endswith('.h5') and f.startswith(datatype+\"_\"+skimtag))]\n",
    "print(\"Will load the following {:d} files:\\n{:s}\".format(len(root_files),\"\\n\".join(sorted(root_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfile = 0\n",
    "nx = 0\n",
    "# Read all the root files with a given skim\n",
    "for f in root_files:\n",
    "    print(\"INFO  \\t Opening file {:d}/{:d}: {:s}\".format(nfile+1,len(root_files),f))\n",
    "    df = pd.read_hdf(indir+\"/\"+f, 'mini')\n",
    "    # Find the unique DSIDs in the file\n",
    "    dsid = np.unique(df.iloc[:,[1]].as_matrix())\n",
    "    # Loop over each DSID and put random selections into training and testing sample \n",
    "    for ids in dsid:\n",
    "        print(\"Doing DSID {:d}. In this file: {:d} new DSIDs\".format(nx+1,len(dsid)))\n",
    "        newdf = df.loc[df['channelNumber'] == ids]\n",
    "        # If X_test/train exists: concatenate, \n",
    "        # If not (i.e. we just wrote to a file): start new ones\n",
    "        try:\n",
    "            midl = newdf.sample(frac=rBackgroundEvents)\n",
    "            X_train = pd.concat([X_train,midl],axis=0)\n",
    "            X_test  = pd.concat([X_test, newdf.drop(midl.index.values)],axis=0)\n",
    "            del [midl]\n",
    "        except:\n",
    "            X_train = newdf.sample(frac=rBackgroundEvents)\n",
    "            X_test  = newdf.drop(X_train.index.values)\n",
    "        del [newdf]\n",
    "        nx += 1\n",
    "        # Dump testing/training samples to file every now and then (here: every tenth DSID)\n",
    "        if nx%10 == 0:\n",
    "            path = indir+\"/testing_bkg_%s_%i.h5\"%(skimtag,nfile)\n",
    "            print(\"Writing to file {:s}\".format(path))\n",
    "            X_test.to_hdf(path,key='result', mode='w')\n",
    "            path = indir+\"/training_bkg_%s_%i.h5\"%(skimtag,nfile)\n",
    "            print(\"Writing to file {:s}\".format(path))\n",
    "            X_train.to_hdf(path,key='result', mode='w')\n",
    "            del [X_test]\n",
    "            del [X_train]\n",
    "    nfile += 1\n",
    "    #if nfile > 2: break\n",
    "    del [df]\n",
    "    \n",
    "# Needed in case we left without writing the last DSIDs to file\n",
    "if nx%10 != 0:\n",
    "    path = indir+\"/testing_bkg_%s_%i.h5\"%(skimtag,nfile)\n",
    "    print(\"Writing to file {:s}\".format(path))\n",
    "    X_test.to_hdf(path,key='result', mode='w')\n",
    "    path = indir+\"/training_bkg_%s_%i.h5\"%(skimtag,nfile)\n",
    "    print(\"Writing to file {:s}\".format(path))\n",
    "    X_train.to_hdf(path,key='result', mode='w')\n",
    "    del [X_test]\n",
    "    del [X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "The following cells show an example on how to plot the variables stored in the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BFrist we retrieve the name of all the training and testing files just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_files = [f for f in listdir(indir) if (f.endswith('.h5') and f.startswith(\"testing_bkg_\"+skimtag))]\n",
    "print(\"TESTING:  Will load the following {:d} files:\\n{:s}\".format(len(testing_files),\"\\n\".join(sorted(testing_files))))\n",
    "training_files = [f for f in listdir(indir) if (f.endswith('.h5') and f.startswith(\"training_bkg_\"+skimtag))]\n",
    "print(\"TRAINING: Will load the following {:d} files:\\n{:s}\".format(len(training_files),\"\\n\".join(sorted(training_files))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the files. If we want to load the whole set (test+trainin) or only one of them can be specified in *load_files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfile = 0\n",
    "load_files = testing_files+training_files\n",
    "for f in load_files:\n",
    "    print(\"INFO  \\t Opening file {:d}/{:d}: {:s}\".format(nfile+1,len(load_files),f))\n",
    "    df = pd.read_hdf(indir+\"/\"+f, 'result')\n",
    "    try:\n",
    "        X_train = pd.concat([X_train,df],axis=0)\n",
    "    except:\n",
    "        X_train = df\n",
    "    del [df]\n",
    "    nfile += 1\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data\n",
    "data_files = [f for f in listdir(datadir) if (f.endswith('.h5') and f.startswith(\"data_\"+skimtag))]\n",
    "print(\"Will load the following {:d} file(s) for data:\\n{:s}\".format(len(data_files),\"\\n\".join(sorted(data_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data (not strictly needed if only 1 file)\n",
    "nfile = 0\n",
    "for f in data_files:\n",
    "    print(\"INFO  \\t Opening file {:d}/{:d}: {:s}\".format(nfile+1,len(data_files),f))\n",
    "    df = pd.read_hdf(datadir+\"/\"+f, 'mini')\n",
    "    try:\n",
    "        X_data = pd.concat([X_data,df],axis=0)\n",
    "    except:\n",
    "        X_data = df\n",
    "    del [df]  \n",
    "    nfile += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plotting specific setting (order of plotting, color of backgrounds).The *stack_order* must have the same keys as in the *MCType* column in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_order = ['Data','Wjets','Top','Diboson','Zjets']\n",
    "samples = {'Wjets':{'color':\"#e55934\"},\n",
    "           'Zjets':{'color':\"#086788\"},\n",
    "           'Top':{'color':\"#9bc53d\"},\n",
    "           'Diboson':{'color':\"#fa7921\"}}\n",
    "bkgs = X_train['MCType'].unique()\n",
    "for s in stack_order:\n",
    "    if \"Data\" in s: continue\n",
    "    if not s in bkgs: print(\"ERROR \\t Key {:s} is not in panda\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the numpy arrays from the panda data frame (specify the variable of interest in *var*). Here the limits, bin width etc. are set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mll = []\n",
    "mc_weights = []\n",
    "mc_colors = []\n",
    "mc_labels = []\n",
    "\n",
    "data_mll = []\n",
    "data_mll_errors = []\n",
    "\n",
    "var = \"lep1_pt\"\n",
    "top = -999\n",
    "\n",
    "nmax = 1000\n",
    "nmin = 0\n",
    "binw = 20\n",
    "\n",
    "data_x = []\n",
    "if not ((nmax-nmin)/binw).is_integer():\n",
    "    print(\"ERROR \\t Limits and bin width are not compatible\")\n",
    "print(int((nmax-nmin)/binw)+1)\n",
    "bins = [nmin + (x*binw) for x in range(int((nmax-nmin)/binw)+1)]\n",
    "for i in range(len(bins)-1):\n",
    "    print(bins[i])\n",
    "    data_x.append(bins[i]+(bins[i+1]-bins[i])/2)\n",
    "#data_x = [((nmin+1) + x*binw) for x in range(int((nmax-nmin)/binw)) ]\n",
    "\n",
    "for s in stack_order:\n",
    "    if s == \"Data\":\n",
    "        data_mll,_ = np.histogram(X_data.as_matrix(columns=X_data.columns[X_data.columns.get_loc(var):X_data.columns.get_loc(var)+1])/1000., bins=bins)\n",
    "        data_mll_errors = np.sqrt(data_mll)\n",
    "    else:\n",
    "        rslt_df = X_train.loc[X_train['MCType'] == s]\n",
    "        mc_mll.append(rslt_df.as_matrix(columns=rslt_df.columns[rslt_df.columns.get_loc(var):rslt_df.columns.get_loc(var)+1])/1000.)\n",
    "        mc_weights.append(rslt_df.as_matrix(columns=rslt_df.columns[rslt_df.columns.get_loc(\"wgt\"):rslt_df.columns.get_loc(\"wgt\")+1]))\n",
    "        mc_colors.append(samples[s]['color'])\n",
    "        mc_labels.append(s)\n",
    "        if np.amax(mc_mll[-1]) > top:\n",
    "            top = np.amax(mc_mll[-1])\n",
    "        del [rslt_df]\n",
    "    print(s)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, do the plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "plt.hist(mc_mll,bins=bins,weights=mc_weights,stacked=True,color=mc_colors, label=mc_labels); #weights=mc_weights,\n",
    "plt.errorbar( x=data_x, y=data_mll, yerr=data_mll_errors, fmt='ko', label='Data')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(r'Events',fontname='sans-serif',horizontalalignment='right',y=1.0,fontsize=11)\n",
    "plt.xlabel(r'$M_{ll}$ [GeV]',fontname='sans-serif',horizontalalignment='right',x=1.0,fontsize=11)\n",
    "\n",
    "plt.ylim(bottom=1,top=top*10)\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.text(0.45,0.97,r'$\\mathbf{{ATLAS}}$ Open Data',ha=\"left\",va=\"top\",family='sans-serif',transform=ax.transAxes,fontsize=13)\n",
    "plt.text(0.45,0.92,'for education only',ha=\"left\",va=\"top\",family='sans-serif',transform=ax.transAxes,style='italic',fontsize=8)\n",
    "plt.text(0.45,0.90,r'$\\sqrt{s}=13\\,\\mathrm{TeV},\\;\\int L\\,dt=10\\,\\mathrm{fb}^{-1}$',ha=\"left\",va=\"top\",family='sans-serif',transform=ax.transAxes)\n",
    "\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mll[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

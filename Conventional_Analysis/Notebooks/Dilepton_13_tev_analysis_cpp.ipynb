{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilepton analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a simple dilepton analysis, quite similar to the notebook called \"Dilepton_analysis_noData.ipynb\", but with some differences. The most obvious difference is that we here also include real data. This example also has a slightly more advanced event selection.  \n",
    "\n",
    "**Notice:** This is *only an example* on how to do this. Feel free to be creative, and to find better and/or more elegant ways of doing the various steps! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Creates a TChain to be used by the Analysis.C class\n",
    "#include <TChain.h>\n",
    "#include <vector>\n",
    "#include <TFile.h>\n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <stdio.h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Sets the verbosity\n",
    "DEBUG = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importarnt**: We need to download some of the data and MC from the [ATLAS OpenData pages](http://opendata.atlas.cern/release/2020/documentation/datasets/files.html). The example below uses the data sets requiring exactly two leptons. Specify the path where you saved the datasets in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Set the path to where data and MC is stored\n",
    "const char *inputpath_MC = \"/ATLAS_opendata/2lep/MC/\";\n",
    "const char *inputpath_DATA = \"/ATLAS_opendata/2lep/Data/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TChain *background = new TChain(\"mini\");\n",
    "TChain *data = new TChain(\"mini\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Reads the information (cross-section, number of simulated events etc.) needed to get the scaling right\n",
    "std::map<TString,std::pair<double,double> > SF;\n",
    "string name, xsec, sumw, eff;\n",
    "std::string ifile;\n",
    "ifile = \"../Input/Files_base.txt\";\n",
    "ifstream input(ifile.c_str());\n",
    "std::string line;\n",
    "while(getline(input,line)){\n",
    "    if (line.find(\"#\") != line.npos )continue; // a # is a comment and not read\n",
    "    istringstream linestream(line);\n",
    "    std::getline(linestream, name, '|');\n",
    "    std::getline(linestream, xsec, '|');\n",
    "    std::getline(linestream, sumw, '|');\n",
    "    std::getline(linestream, eff);\n",
    "    if(DEBUG)cout << name << \" \" << xsec << \" \" << sumw << \" \" << eff << endl;\n",
    "    float sumw_eff = atof(sumw.c_str()) * atof(eff.c_str());\n",
    "    SF[TString(name)] = std::make_pair(atof(xsec.c_str()), sumw_eff);    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// We also need to categorise the various background files into categories (ttbar,diboson,singletop etc.)\n",
    "vector<TString> Backgrounds; \n",
    "std::map<TString,std::pair<TString,int> > samples;\n",
    "string name, cat, dsid;\n",
    "std::string ifile;\n",
    "ifile = \"../Input/Infofile.txt\";\n",
    "ifstream input(ifile.c_str());\n",
    "std::string line;\n",
    "while(getline(input,line)){\n",
    "    if (line.find(\"#\") != line.npos )continue; // a # is a comment and not read\n",
    "    istringstream linestream(line);\n",
    "    std::getline(linestream, name,'|');\n",
    "    std::getline(linestream, cat,'|');\n",
    "    std::getline(linestream, dsid,'|');\n",
    "    if(DEBUG)cout << name << \" \" << cat << \" \" << dsid << endl;\n",
    "    samples[TString(name)] = std::make_pair(TString(cat), atof(dsid.c_str()));\n",
    "    if(!(std::count(Backgrounds.begin(), Backgrounds.end(), TString(cat)))){\n",
    "    Backgrounds.push_back(TString(cat));\n",
    "    }\n",
    "    //float sumw_eff = atof(sumw.c_str()) * atof(eff.c_str());\n",
    "    //SF[TString(name)] = std::make_pair(atof(xsec.c_str()), sumw_eff);    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(DEBUG){\n",
    "    for (const auto& kv: samples) {\n",
    "        std::cout << \"Key: \" << kv.first << \" Value: \" << (kv.second).first << \", \" << (kv.second).second<<std::endl;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Finds all the background files in the path specified above and categorised\n",
    "const char *ext=\".root\";\n",
    "int nfiles_MC = 0;\n",
    "TSystemDirectory dir(inputpath_MC, inputpath_MC); \n",
    "TList *files = dir.GetListOfFiles(); \n",
    "if (files) { \n",
    "    TSystemFile *file; \n",
    "    TString fname; \n",
    "    TIter next(files); \n",
    "    while ((file=(TSystemFile*)next())) { \n",
    "        fname = file->GetName(); \n",
    "        if (!file->IsDirectory() && fname.EndsWith(ext)) \n",
    "        {\n",
    "            //cout << fname.Data() << endl; \n",
    "            TObjArray *tx = fname.Tokenize(\".\");\n",
    "            if(samples.find(((TObjString *)(tx->At(1)))->String()) == samples.end()){\n",
    "                if(DEBUG)cout<<\"File \"<<fname<<\" not included in analysis\"<<endl;\n",
    "                continue;\n",
    "            }\n",
    "            if(DEBUG)cout<<\"Adding \"<<TString(inputpath_MC)+fname<<endl;\n",
    "            background->Add(TString(inputpath_MC)+fname);\n",
    "            nfiles_MC += 1;\n",
    "            \n",
    "        } \n",
    "    } \n",
    "} \n",
    "printf(\"MC: Added %i files with %lld events\\n\",nfiles_MC,background->GetEntries());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Reads all available data\n",
    "const char *ext=\".root\";\n",
    "TSystemDirectory dir(inputpath_DATA, inputpath_DATA); \n",
    "TList *files = dir.GetListOfFiles(); \n",
    "int nfiles_data = 0;\n",
    "if (files) { \n",
    "    TSystemFile *file; \n",
    "    TString fname; \n",
    "    TIter next(files); \n",
    "    while ((file=(TSystemFile*)next())) { \n",
    "        fname = file->GetName(); \n",
    "        if (!file->IsDirectory() && fname.EndsWith(ext)) \n",
    "        {\n",
    "            //cout << fname.Data() << endl; \n",
    "            TObjArray *tx = fname.Tokenize(\".\");\n",
    "            if(DEBUG)cout<<\"Adding \"<<TString(inputpath_MC)+fname<<endl;\n",
    "            data->Add(TString(inputpath_DATA)+fname);\n",
    "            nfiles_data += 1;\n",
    "            \n",
    "        } \n",
    "    } \n",
    "} \n",
    "printf(\"DATA: Added %i files with %lld events\\n\",nfiles_data,data->GetEntries());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the variables we want to include in the analysis, and link them to branches in the TTree. A few things to notice at this point: \n",
    "-  In this example we will only study events with two leptons, so the vectorial variables only need to be two dimensional. \n",
    "-  The variables are here given names corresponding to the branches in the TTree. This is not necessary, so if you want to give them other names you are free to do so. \n",
    "-  The variable called \"channelNumber\" is the same as we have called \"dataset ID\" above. These terms are used interchangeably. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// It is important to set the pointers to zero. If not you will get a segmentation violation when running\n",
    " unsigned int lep_n;\n",
    "  vector<int> *lep_charge = 0;\n",
    "  int channelNumber;\n",
    "  vector<UInt_t> *lep_type = 0;\n",
    "  vector<float> *lep_pt = 0;\n",
    "  vector<float> *lep_E = 0;\n",
    "  vector<float> *lep_phi = 0;\n",
    "  vector<float> *lep_eta = 0;\n",
    "  vector<float> *jet_MV2c10 = 0;\n",
    "  vector<float> *lep_etcone20 = 0;\n",
    "  vector<float> *lep_ptcone30 = 0;  \n",
    "  float met_et;\n",
    "  vector<bool> *lep_trigMatched = 0;\n",
    "  bool trigE;\n",
    "  bool trigM; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float scaleFactor_PILEUP; \n",
    "float scaleFactor_ELE;\n",
    "float scaleFactor_MUON;\n",
    "float scaleFactor_BTAG;\n",
    "float scaleFactor_LepTRIGGER;\n",
    "float mcWeight;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " background->SetBranchAddress(\"lep_n\",      &lep_n);\n",
    " \n",
    "  background->SetBranchAddress(\"lep_charge\", &lep_charge);\n",
    "  background->SetBranchAddress(\"lep_type\",   &lep_type);\n",
    "  background->SetBranchAddress(\"lep_pt\",     &lep_pt);\n",
    "  background->SetBranchAddress(\"lep_eta\",    &lep_eta);\n",
    "  background->SetBranchAddress(\"lep_phi\",    &lep_phi);\n",
    "  background->SetBranchAddress(\"lep_E\",      &lep_E);\n",
    "  background->SetBranchAddress(\"met_et\",     &met_et); \n",
    "  background->SetBranchAddress(\"channelNumber\", &channelNumber);\n",
    "  background->SetBranchAddress(\"mcWeight\", &mcWeight); \n",
    "  background->SetBranchAddress(\"scaleFactor_PILEUP\", &scaleFactor_PILEUP ); \n",
    "  background->SetBranchAddress(\"scaleFactor_ELE\", &scaleFactor_ELE ); \n",
    "  background->SetBranchAddress(\"scaleFactor_MUON\", &scaleFactor_MUON ); \n",
    "  background->SetBranchAddress(\"scaleFactor_BTAG\", &scaleFactor_BTAG ); \n",
    "  background->SetBranchAddress(\"scaleFactor_LepTRIGGER\", &scaleFactor_LepTRIGGER ); \n",
    "  background->SetBranchAddress(\"lep_ptcone30\", &lep_ptcone30); \n",
    "  background->SetBranchAddress(\"lep_etcone20\", &lep_etcone20); \n",
    "  background->SetBranchAddress(\"trigE\", &trigE); \n",
    "  background->SetBranchAddress(\"trigM\", &trigM); \n",
    "  background->SetBranchAddress(\"jet_MV2c10\", &jet_MV2c10); \n",
    "\n",
    "  // For data \n",
    "  data->SetBranchAddress(\"lep_n\",      &lep_n);\n",
    "  data->SetBranchAddress(\"lep_charge\", &lep_charge);\n",
    "  data->SetBranchAddress(\"lep_type\",   &lep_type);\n",
    "  data->SetBranchAddress(\"lep_pt\",     &lep_pt);\n",
    "  data->SetBranchAddress(\"lep_eta\",    &lep_eta);\n",
    "  data->SetBranchAddress(\"lep_phi\",    &lep_phi);\n",
    "  data->SetBranchAddress(\"lep_E\",      &lep_E);\n",
    "  data->SetBranchAddress(\"met_et\",     &met_et); \n",
    "  data->SetBranchAddress(\"channelNumber\", &channelNumber);\n",
    "  data->SetBranchAddress(\"trigE\", &trigE); \n",
    "  data->SetBranchAddress(\"trigM\", &trigM); \n",
    "  data->SetBranchAddress(\"lep_trigMatched\", &lep_trigMatched); \n",
    "  data->SetBranchAddress(\"lep_ptcone30\", &lep_ptcone30); \n",
    "  data->SetBranchAddress(\"lep_etcone20\", &lep_etcone20); \n",
    "  data->SetBranchAddress(\"jet_MV2c10\", &jet_MV2c10); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making (a lot of) histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read our dataset we want to start analyzing the data. To do so we need to put the data into histograms. For reasons that will become clear later in the analysis we must (for each variable) make one histogram per dataset ID. (We have 31 background samples, so if we want to study 10 variables we have to make 310 histograms!) A very elegant way of dealing with all these histograms is by using [map](http://www.cplusplus.com/reference/map/map/)s (the C$++$ equivalent of Python dictionaries). Below we define one map for each variable. Here the *key values* are the dataset IDs, while the *mapped values* are the histograms.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map<Int_t, TH1*> hist_mll; \n",
    "map<Int_t, TH1*> hist_lep_pt; \n",
    "map<Int_t, TH1*> hist_met;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const auto& kv: samples) {\n",
    "    int dsid = (kv.second).second;\n",
    "    hist_mll[dsid] = new TH1F(); \n",
    "    hist_lep_pt[dsid] = new TH1F(); \n",
    "    hist_met[dsid] = new TH1F();\n",
    "    hist_mll[dsid]->SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "    hist_lep_pt[dsid]->SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "    hist_met[dsid]->SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "    hist_mll[dsid]->SetBins(20,0,500); \n",
    "    hist_lep_pt[dsid]->SetBins(20,0,1000);\n",
    "    hist_met[dsid]->SetBins(20,0,500); \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH1F *hist_mll_d = new TH1F(); \n",
    "TH1F *hist_lep_pt_d = new TH1F(); \n",
    "TH1F *hist_met_d = new TH1F(); \n",
    "hist_mll_d->SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "hist_lep_pt_d->SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "hist_met_d->SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "hist_mll_d->SetBins(20,0,500); \n",
    "hist_lep_pt_d->SetBins(20,0,1000);\n",
    "hist_met_d->SetBins(20,0,500); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fill the histograms \n",
    "We can now loop over all events in our dataset, implement desired cuts, and fill the histograms we created above. In this example we choose only events containing exactly to same flavour leptons with opposite charge (i.e. $e^+e^-$ or $\\mu^+\\mu^-$). \n",
    "Before starting the loop we extract the total number of entries (events) in the TChain. We also make [TLorentzVector](https://root.cern.ch/doc/master/classTLorentzVector.html)s, which are very practical for handling the kinematics of the leptons, e.g. calculating the invariant mass of the two leptons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLorentzVector l1, l2, dileptons; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TChain *dataset = new TChain(\"mini\"); \n",
    "int isData = 0; \n",
    "int nentries; \n",
    "Float_t W; \n",
    "int n_bjets; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Reset histograms (in case you have filled them before) \n",
    "for(const auto& kv: samples){ \n",
    "    int dsid = (kv.second).second;\n",
    "    hist_mll[dsid]->Reset(); \n",
    "    hist_lep_pt[dsid]->Reset(); \n",
    "    hist_met[dsid]->Reset();\n",
    "}\n",
    "\n",
    "hist_mll_d->Reset(); \n",
    "hist_lep_pt_d->Reset(); \n",
    "hist_met_d->Reset(); \n",
    "std::cout<<\"isData = \"<<isData<<std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main cell for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isData = 0;\n",
    "for (Long64_t i = 0; i < background->GetEntries(); i++){\n",
    "    \n",
    "    if( i%1000000 == 0 && i>0){ std::cout << i/1000000 << \" million events processed\" << std::endl;}\n",
    "    \n",
    "    background->GetEntry(i);\n",
    "     // Require \"good leptons\":\n",
    "    /**\n",
    "      if(lep_n != 2){ continue; }\n",
    "\n",
    "      if( lep_pt->at(0)/1000.0 < 25 ){ continue; }\n",
    "\n",
    "    \n",
    "      if( lep_etcone20->at(0)/lep_pt->at(0) > 0.15 ){ continue; }\n",
    "      if( lep_ptcone30->at(0)/lep_pt->at(0) > 0.15 ){ continue; }\n",
    "\n",
    "      if( lep_pt->at(1)/1000.0 < 25 ){ continue; }\n",
    "      if( lep_etcone20->at(1)/lep_pt->at(1) > 0.15 ){ continue; }\n",
    "      if( lep_ptcone30->at(1)/lep_pt->at(1) > 0.15 ){ continue; }\n",
    "*/\n",
    "      // Event selection: \n",
    "      // Cut #1: Require (exactly) 2 leptons\n",
    "    cout<<\"lepN = \"<<lep_n<<endl;\n",
    "      if(lep_n != 2){ continue; }\n",
    "    cout<<\"charge = \"<<lep_charge->at(0)<<endl;\n",
    "      // Cut #2: Require opposite charge\n",
    "      if(lep_charge->at(0) == lep_charge->at(1)){ continue; }\n",
    "      // Cut #3: Require same flavour (2 electrons or 2 muons)\n",
    "      if(lep_type->at(0) != lep_type->at(1)){ continue; }\n",
    "\n",
    "      // Set Lorentz vectors: \n",
    "      l1.SetPtEtaPhiE(lep_pt->at(0)/1000., lep_eta->at(0), lep_phi->at(0), lep_E->at(0)/1000.);\n",
    "      l2.SetPtEtaPhiE(lep_pt->at(1)/1000., lep_eta->at(1), lep_phi->at(1), lep_E->at(1)/1000.);\n",
    "      // Variables are stored in the TTree with unit MeV, so we need to divide by 1000 \n",
    "      // to get GeV, which is a more practical and commonly used unit. \n",
    "\n",
    "      dileptons = l1 + l2;\n",
    "    Float_t scaleFactor = 1.0;\n",
    "    if(!isData){\n",
    "        scaleFactor = mcWeight*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER*scaleFactor_PILEUP;\n",
    "    }\n",
    "    if(isData){\n",
    "        hist_mll_d->Fill(dileptons.M(),scaleFactor);\n",
    "        hist_lep_pt_d->Fill(l1.Pt(),scaleFactor);\n",
    "        hist_lep_pt_d->Fill(l2.Pt(),scaleFactor);\n",
    "        hist_met_d->Fill(met_et/1000.,scaleFactor);\n",
    "    }else{\n",
    "        \n",
    "        hist_mll[channelNumber]->Fill(dileptons.M(),scaleFactor);\n",
    "        hist_lep_pt[channelNumber]->Fill(l1.Pt(),scaleFactor);\n",
    "        hist_lep_pt[channelNumber]->Fill(l2.Pt(),scaleFactor);\n",
    "        hist_met[channelNumber]->Fill(met_et/1000.,scaleFactor);\n",
    "    }\n",
    "    if(i>10000)break;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now done the \"heavy lifting\" of an analysis, i.e. looping through all the events. Usually in such an analysis we create new ROOT files where we store the histograms we made above, and then analyse the output in a separate program/script. The advantage of doing this is that you can do the rest of the analysis in another language, e.g. Python, since we are done with part that requires the speed of C$++$. If you want to write ROOT files you can check out the [TFile](https://root.cern.ch/doc/master/classTFile.html) class reference. In this example we will however carry on in C$++$. But even if you only work in C++ it can be practical to write the histograms to file, so that you don't need to run the loop _every time_ you open the notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scale and classify the histograms (MC only) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are ready to make plots we need to do some further processing of the histograms we made above. The information necessary for doing the two steps below is found in the file **Infofile.txt**.   \n",
    "1. We need to **scale** the histograms to the right cross section and luminosity. Why? When making the MC samples a certain number of events is simulated, which will usually not correspond to the number of events in our data. The expected number of events from a certain kind of process is given by $N=\\sigma L$, where $\\sigma$ is the cross section and $L$ is the integrated luminosity. Therefore we need to scale each histogram by a scale factor <br> <br>\n",
    "$$sf = \\frac{N}{N_{MC}} = \\frac{ \\sigma L }{N_{MC}},$$ <br>  where $N_{MC}$ is the number of generated MC events.  <br> <br>\n",
    "2. We also need to **classify** the background processes into different categories. This is necessary when we eventually want to make the characteristic colorful background plots you might have seen before.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Make new histograms \n",
    "Maybe a bit depressingly we have to make a set of new histograms, this time corresponding to the different background categories, instead of the dataset IDs. Notice that these new histograms are made in a very similar way as above, i.e. with the same range and binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map<TString, TH1*> H_mll; \n",
    "map<TString, TH1*> H_lep_pt; \n",
    "map<TString, TH1*> H_met;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & kv:samples){\n",
    "    cat = (kv.second).first;\n",
    "    H_mll[cat] = new TH1F(); \n",
    "    H_lep_pt[cat] = new TH1F(); \n",
    "    H_met[cat] = new TH1F(); \n",
    "    H_mll[cat]->SetNameTitle(\"hist_mll\", \"Invariant mass\"); \n",
    "    H_lep_pt[cat]->SetNameTitle(\"hist_lep_pt\", \"Lepton pT\"); \n",
    "    H_met[cat]->SetNameTitle(\"hist_met\", \"Missing ET\");\n",
    "    H_mll[cat]->SetBins(20,0,500); \n",
    "    H_lep_pt[cat]->SetBins(20,0,1000);\n",
    "    H_met[cat]->SetBins(20,0,500); \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float L = 1000.6; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto & kv:samples){\n",
    "    cat = (kv.second).first;\n",
    "    H_mll[cat]->Reset(); \n",
    "    H_lep_pt[cat]->Reset(); \n",
    "    H_met[cat]->Reset();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double sf;\n",
    "std::pair<TString,int> pairs;\n",
    "for(const auto & kv:SF){\n",
    "    sf = (kv.second).first*L/(kv.second).second;  \n",
    "    TString name = kv.first;\n",
    "      \n",
    "    // Check that it is in the samples we want to include\n",
    "    if ( samples.find(name) == samples.end() ) {\n",
    "     cout<<\"Could not find \"<<name<<\" in samples dic\"<<endl;  \n",
    "     continue;\n",
    "    }\n",
    "    // Get category and dsid\n",
    "    pairs = samples.at(name);\n",
    "    TString type = pairs.first;\n",
    "    int dsid = pairs.second;\n",
    "    \n",
    "    // Scale dsid histogram\n",
    "    hist_mll[dsid]->Scale(sf); \n",
    "    hist_lep_pt[dsid]->Scale(sf); \n",
    "    hist_met[dsid]->Scale(sf); \n",
    "    // Add dsid histogram to correct category historgram\n",
    "    H_mll[type]->Add(hist_mll[dsid]); \n",
    "    H_lep_pt[type]->Add(hist_lep_pt[dsid]); \n",
    "    H_met[type]->Add(hist_met[dsid]); \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Color the histograms \n",
    "Make yet another map, this time containing the colors you want the backgrounds to have, and then set the colors of your histograms. Note that colors are defined by integers in ROOT. If you are not happy with the colors chosen below you can have look at the [TColor](https://root.cern.ch/doc/master/classTColor.html) class reference for more options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map<TString, Int_t> colors; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors[\"Diboson\"] = kGreen; \n",
    "colors[\"Zjets\"] = kYellow; \n",
    "colors[\"ttbar\"] = kRed;\n",
    "colors[\"singleTop\"] = kBlue-7; \n",
    "colors[\"Wjets\"] = kBlue+3; \n",
    "colors[\"topX\"] = kOrange+1; \n",
    "colors[\"Higgs\"] = kMagenta; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto h:Backgrounds){\n",
    "    H_mll[h]->SetFillColor(colors[h]); \n",
    "    H_met[h]->SetFillColor(colors[h]);\n",
    "    H_lep_pt[h]->SetFillColor(colors[h]);\n",
    "    \n",
    "    H_mll[h]->SetLineColor(colors[h]); \n",
    "    H_met[h]->SetLineColor(colors[h]);\n",
    "    H_lep_pt[h]->SetLineColor(colors[h]);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stack and plot the histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have arrived to the part where we can plot the results of all the work done above. For each variable we need to stack the backgrounds on top of each other, which is done by using the [THStack](https://root.cern.ch/doc/master/classTHStack.html) class. In the example below we do this for two variables; invariant mass and missing $E_T$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THStack *stack_mll = new THStack(\"Invariant mass\", \"\");\n",
    "THStack *stack_met = new THStack(\"Missing ET\", \"\"); \n",
    "THStack *stack_lep_pt = new THStack(\"Lepton pT\", \"\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(const auto h: Backgrounds){\n",
    "    stack_mll->RecursiveRemove(H_mll[h]); // Remove previously stacked histograms  \n",
    "    stack_met->RecursiveRemove(H_met[h]);\n",
    "    stack_lep_pt->RecursiveRemove(H_lep_pt[h]);\n",
    "    stack_mll->Add(H_mll[h]); \n",
    "    stack_met->Add(H_met[h]);\n",
    "    stack_lep_pt->Add(H_lep_pt[h]); \n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a legend (see [TLegend](https://root.cern.ch/doc/master/classTLegend.html)), and add  the different backgrounds. Next we make a canvas (see [TCanvas](https://root.cern.ch/doc/master/classTCanvas.html)), which is allways necessary when we want to make a plot. Then you draw the stack and the legend, and display them by drawing the canvas. We can also specify axis labels and a bunch of other stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gStyle->SetLegendBorderSize(0); // Remove (default) border around legend \n",
    "TLegend *leg = new TLegend(0.65, 0.60, 0.9, 0.85); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg->Clear();\n",
    "for(const auto h: Backgrounds){\n",
    "    leg->AddEntry(H_mll[h], h, \"f\");  // Add your histograms to the legend\n",
    "} \n",
    "leg->AddEntry(hist_mll_d, \"Data\", \"lep\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCanvas *C = new TCanvas(\"c\", \"c\", 600, 600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gPad->SetLogy(); // Set logarithmic y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mll_d->SetLineColor(kBlack); \n",
    "hist_mll_d->SetMarkerStyle(kFullCircle); \n",
    "hist_mll_d->SetMarkerColor(kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_mll->Draw(\"hist\"); \n",
    "stack_mll->SetMaximum(1E6); \n",
    "stack_mll->GetYaxis()->SetTitle(\"# events\");\n",
    "stack_mll->GetYaxis()->SetTitleOffset(1.3); \n",
    "stack_mll->GetXaxis()->SetTitle(\"m_{ll} (GeV)\");\n",
    "stack_mll->GetXaxis()->SetTitleOffset(1.3);\n",
    "hist_mll_d->Draw(\"same E\"); \n",
    "leg->Draw();\n",
    "C->Draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_met_d->SetLineColor(kBlack); \n",
    "hist_met_d->SetMarkerStyle(kFullCircle); \n",
    "hist_met_d->SetMarkerColor(kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_met->Draw(\"hist\"); \n",
    "stack_met->SetMaximum(1E6); \n",
    "stack_met->SetMinimum(1E-2); \n",
    "stack_met->GetYaxis()->SetTitle(\"# events\");\n",
    "stack_met->GetYaxis()->SetTitleOffset(1.3); \n",
    "stack_met->GetXaxis()->SetTitle(\"E_{T}^{miss} (GeV)\");\n",
    "stack_met->GetXaxis()->SetTitleOffset(1.3);\n",
    "hist_met_d->Draw(\"same e\"); \n",
    "leg->Draw();\n",
    "C->Draw(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lep_pt_d->SetLineColor(kBlack); \n",
    "hist_lep_pt_d->SetMarkerStyle(kFullCircle); \n",
    "hist_lep_pt_d->SetMarkerColor(kBlack); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_lep_pt->Draw(\"hist\"); \n",
    "stack_lep_pt->SetMaximum(1E6); \n",
    "stack_lep_pt->GetYaxis()->SetTitle(\"# events\");\n",
    "stack_lep_pt->GetYaxis()->SetTitleOffset(1.3); \n",
    "stack_lep_pt->GetXaxis()->SetTitle(\"p_{T} (GeV)\");\n",
    "stack_lep_pt->GetXaxis()->SetTitleOffset(1.3);\n",
    "hist_lep_pt_d->Draw(\"same e\"); \n",
    "leg->Draw();\n",
    "C->Draw(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
